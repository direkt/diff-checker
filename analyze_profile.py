#!/usr/bin/env python3
"""
Dremio Query Profile Analyzer (FIXED VERSION)
Finds the longest running operators and phases from a query profile JSON file.

VALIDATED: Operator type mappings validated against Dremio codebase
Source: dremio/oss/protocol/src/main/protobuf/UserBitShared.proto (lines 773-845)
"""

import json
import sys
from typing import Dict, List, Tuple, Any
from dataclasses import dataclass
from pathlib import Path

@dataclass
class OperatorTiming:
    operator_id: int
    operator_type: int
    operator_name: str
    setup_nanos: int
    process_nanos: int
    wait_nanos: int
    total_nanos: int
    fragment_id: int
    minor_fragment_id: int

@dataclass
class PhaseTiming:
    phase_name: str
    duration_millis: int

def get_operator_type_name(operator_type: int) -> str:
    """
    Map operator type ID to human-readable name.
    
    FIXED: Complete mapping based on CoreOperatorType enum from:
    dremio/oss/protocol/src/main/protobuf/UserBitShared.proto (lines 773-845)
    
    All 69 operator types (0-68) are now correctly mapped.
    """
    operator_types = {
        0: "SingleSender",
        1: "BroadcastSender", 
        2: "Filter",
        3: "HashAggregate",  # FIXED: was "HashAgg"
        4: "HashJoin",
        5: "MergeJoin",
        6: "HashPartitionSender",
        7: "Limit",
        8: "MergingReceiver",
        9: "OrderedPartitionSender",
        10: "Project",
        11: "UnorderedReceiver",
        12: "RangeSender",
        13: "Screen",
        14: "SelectionVectorRemover",
        15: "StreamingAggregate",
        16: "TopNSort",
        17: "ExternalSort",
        18: "Trace",
        19: "Union",
        20: "OldSort",
        21: "ParquetRowGroupScan",
        22: "HiveSubScan",
        23: "SystemTableScan",
        24: "MockSubScan",
        25: "ParquetWriter",
        26: "DirectSubScan",
        27: "TextWriter",
        28: "TextSubScan",
        29: "JsonSubScan",
        30: "InfoSchemaSubScan",
        31: "ComplexToJson",
        32: "ProducerConsumer",
        33: "HbaseSubScan",
        34: "Window",
        35: "NestedLoopJoin",
        36: "AvroSubScan",
        37: "MongoSubScan",
        38: "ElasticsearchSubScan",
        39: "ElasticsearchAggregatorSubScan",
        40: "Flatten",
        41: "ExcelSubScan",
        42: "ArrowSubScan",
        43: "ArrowWriter",
        44: "JsonWriter",
        45: "ValuesReader",
        46: "ConvertFromJson",
        47: "JdbcSubScan",
        48: "DictionaryLookup",
        49: "WriterCommitter",
        50: "RoundRobinSender",
        51: "BoostParquet",
        52: "IcebergSubScan",  # FIXED: was "IcebergManifestList"
        53: "TableFunction",
        54: "DeltalakeSubScan",
        55: "DirListingSubScan",
        56: "IcebergWriterCommitter",
        57: "GrpcWriter",
        58: "ManifestWriter",
        59: "FlightSubScan",
        60: "BridgeFileWriterSender",
        61: "BridgeFileReaderReceiver",
        62: "BridgeFileReader",
        63: "IcebergManifestWriter",
        64: "IcebergMetadataFunctionsReader",
        65: "IcebergSnapshotsSubScan",
        66: "NessieCommitsSubScan",
        67: "SmallFileCombinationWriter",
        68: "ArrowWriterAuxiliary"
    }
    return operator_types.get(operator_type, f"Unknown({operator_type})")

def analyze_operators(profile_data: Dict[str, Any]) -> List[OperatorTiming]:
    """Extract and analyze operator timings from the profile"""
    operators = []
    
    fragment_profiles = profile_data.get("fragmentProfile", [])
    
    for fragment in fragment_profiles:
        major_fragment_id = fragment.get("majorFragmentId", 0)
        minor_fragments = fragment.get("minorFragmentProfile", [])
        
        for minor_fragment in minor_fragments:
            minor_fragment_id = minor_fragment.get("minorFragmentId", 0)
            operator_profiles = minor_fragment.get("operatorProfile", [])
            
            for op in operator_profiles:
                operator_id = op.get("operatorId", 0)
                operator_type = op.get("operatorType", 0)
                setup_nanos = op.get("setupNanos", 0)
                process_nanos = op.get("processNanos", 0)
                wait_nanos = op.get("waitNanos", 0)
                
                total_nanos = setup_nanos + process_nanos + wait_nanos
                operator_name = get_operator_type_name(operator_type)
                
                operators.append(OperatorTiming(
                    operator_id=operator_id,
                    operator_type=operator_type,
                    operator_name=operator_name,
                    setup_nanos=setup_nanos,
                    process_nanos=process_nanos,
                    wait_nanos=wait_nanos,
                    total_nanos=total_nanos,
                    fragment_id=major_fragment_id,
                    minor_fragment_id=minor_fragment_id
                ))
    
    return operators

def analyze_phases(profile_data: Dict[str, Any]) -> List[PhaseTiming]:
    """Extract and analyze phase timings from the profile"""
    phases = []
    
    plan_phases = profile_data.get("planPhases", [])
    
    for phase in plan_phases:
        phase_name = phase.get("phaseName", "Unknown")
        duration_millis = phase.get("durationMillis", 0)
        
        phases.append(PhaseTiming(
            phase_name=phase_name,
            duration_millis=duration_millis
        ))
    
    return phases

def format_time(nanos: int) -> str:
    """Format nanoseconds into human-readable time"""
    if nanos < 1000:
        return f"{nanos}ns"
    elif nanos < 1_000_000:
        return f"{nanos/1000:.2f}Î¼s"
    elif nanos < 1_000_000_000:
        return f"{nanos/1_000_000:.2f}ms"
    else:
        return f"{nanos/1_000_000_000:.2f}s"

def format_millis(millis: int) -> str:
    """Format milliseconds into human-readable time"""
    if millis < 1000:
        return f"{millis}ms"
    else:
        return f"{millis/1000:.2f}s"

def print_top_operators(operators: List[OperatorTiming], top_n: int = 10):
    """Print the top N longest running operators"""
    print(f"\nðŸ”¥ TOP {top_n} LONGEST RUNNING OPERATORS")
    print("=" * 90)
    
    # Sort by total time
    sorted_operators = sorted(operators, key=lambda x: x.total_nanos, reverse=True)
    
    print(f"{'Rank':<4} {'Fragment':<8} {'Op ID':<5} {'Type':<25} {'Setup':<12} {'Process':<12} {'Wait':<12} {'Total':<12}")
    print("-" * 90)
    
    for i, op in enumerate(sorted_operators[:top_n], 1):
        print(f"{i:<4} {op.fragment_id}-{op.minor_fragment_id:<6} {op.operator_id:<5} {op.operator_name:<25} "
              f"{format_time(op.setup_nanos):<12} {format_time(op.process_nanos):<12} "
              f"{format_time(op.wait_nanos):<12} {format_time(op.total_nanos):<12}")

def print_top_phases(phases: List[PhaseTiming], top_n: int = 10):
    """Print the top N longest running phases"""
    print(f"\nâ±ï¸  TOP {top_n} LONGEST RUNNING PHASES")
    print("=" * 60)
    
    # Sort by duration
    sorted_phases = sorted(phases, key=lambda x: x.duration_millis, reverse=True)
    
    print(f"{'Rank':<4} {'Phase Name':<40} {'Duration':<12}")
    print("-" * 60)
    
    for i, phase in enumerate(sorted_phases[:top_n], 1):
        print(f"{i:<4} {phase.phase_name:<40} {format_millis(phase.duration_millis):<12}")

def print_summary_stats(profile_data: Dict[str, Any], operators: List[OperatorTiming], phases: List[PhaseTiming]):
    """Print overall summary statistics"""
    print("\nðŸ“Š QUERY EXECUTION SUMMARY")
    print("=" * 50)
    
    # Query timing
    start_time = profile_data.get("start", 0)
    end_time = profile_data.get("end", 0)
    total_query_time = end_time - start_time
    
    planning_start = profile_data.get("planningStart", 0)
    planning_end = profile_data.get("planningEnd", 0)
    planning_time = planning_end - planning_start
    
    print(f"Total Query Time: {format_millis(total_query_time)}")
    print(f"Planning Time: {format_millis(planning_time)}")
    
    # Operator stats
    if operators:
        total_operator_time = sum(op.total_nanos for op in operators)
        max_operator_time = max(op.total_nanos for op in operators)
        avg_operator_time = total_operator_time / len(operators)
        
        print(f"Total Operator Time: {format_time(total_operator_time)}")
        print(f"Max Operator Time: {format_time(max_operator_time)}")
        print(f"Avg Operator Time: {format_time(int(avg_operator_time))}")
        print(f"Number of Operators: {len(operators)}")
    
    # Phase stats
    if phases:
        total_phase_time = sum(phase.duration_millis for phase in phases)
        max_phase_time = max(phase.duration_millis for phase in phases)
        
        print(f"Total Phase Time: {format_millis(total_phase_time)}")
        print(f"Max Phase Time: {format_millis(max_phase_time)}")
        print(f"Number of Phases: {len(phases)}")

def print_operator_type_distribution(operators: List[OperatorTiming]):
    """Print distribution of operator types in the query - NEW FEATURE"""
    print(f"\nðŸ“ˆ OPERATOR TYPE DISTRIBUTION")
    print("=" * 70)
    
    type_counts = {}
    type_times = {}
    
    for op in operators:
        op_name = op.operator_name
        type_counts[op_name] = type_counts.get(op_name, 0) + 1
        type_times[op_name] = type_times.get(op_name, 0) + op.total_nanos
    
    # Sort by total time
    sorted_types = sorted(type_times.items(), key=lambda x: x[1], reverse=True)
    
    print(f"{'Operator Type':<25} {'Count':<6} {'Total Time':<15} {'Avg Time':<12}")
    print("-" * 70)
    
    for op_name, total_time in sorted_types:
        count = type_counts[op_name]
        avg_time = total_time / count
        print(f"{op_name:<25} {count:<6} {format_time(total_time):<15} {format_time(int(avg_time)):<12}")

def analyze_profile_file(file_path: str, top_n: int = 10):
    """Main function to analyze a profile file"""
    try:
        with open(file_path, 'r') as f:
            profile_data = json.load(f)
        
        print(f"ðŸ” ANALYZING QUERY PROFILE: {file_path}")
        print(f"Query ID: {profile_data.get('id', {}).get('part1', 'Unknown')}")
        print(f"User: {profile_data.get('user', 'Unknown')}")
        print(f"âœ… FIXED: All operator type mappings validated against Dremio codebase")
        
        # Analyze operators and phases
        operators = analyze_operators(profile_data)
        phases = analyze_phases(profile_data)
        
        # Print results
        print_summary_stats(profile_data, operators, phases)
        print_operator_type_distribution(operators)  # NEW: Added operator distribution
        print_top_operators(operators, top_n)
        print_top_phases(phases, top_n)
        
        # Find the single longest running item
        if operators:
            longest_operator = max(operators, key=lambda x: x.total_nanos)
            print(f"\nðŸ† LONGEST RUNNING OPERATOR:")
            print(f"   Fragment {longest_operator.fragment_id}-{longest_operator.minor_fragment_id}, "
                  f"Operator {longest_operator.operator_id} ({longest_operator.operator_name}): "
                  f"{format_time(longest_operator.total_nanos)}")
        
        if phases:
            longest_phase = max(phases, key=lambda x: x.duration_millis)
            print(f"\nðŸ† LONGEST RUNNING PHASE:")
            print(f"   {longest_phase.phase_name}: {format_millis(longest_phase.duration_millis)}")
            
    except FileNotFoundError:
        print(f"âŒ Error: File '{file_path}' not found")
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"âŒ Error: Invalid JSON in file '{file_path}': {e}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ Error analyzing profile: {e}")
        sys.exit(1)

def main():
    """Main entry point"""
    if len(sys.argv) < 2:
        print("Usage: python analyze_profile.py <profile_file.json> [top_n]")
        print("Example: python analyze_profile.py profile_attempt_0.json 5")
        print("\nâœ… FIXED VERSION: All operator type mappings corrected and validated")
        sys.exit(1)
    
    file_path = sys.argv[1]
    top_n = int(sys.argv[2]) if len(sys.argv) > 2 else 10
    
    analyze_profile_file(file_path, top_n)

if __name__ == "__main__":
    main() 